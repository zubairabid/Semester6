{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = ['Training','Development','Testing']\n",
    "dir_prefix = os.path.join(os.getcwd(), 'UDData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# sent_id = dev-s1'] 1\n",
      "['# text = रामायण काल में भगवान राम के पुत्र कुश की राजधानी कुशावती को 483 ईसा पूर्व बुद्ध ने अपने अंतिम विश्राम के लिए चुना ।'] 1\n",
      "['1', 'रामायण', 'रामायण', 'PROPN', 'NNPC', 'Case=Nom|Gender=Masc|Number=Sing|Person=3', '2', 'compound', '_', 'Vib=0|Tam=0|ChunkId=NP|ChunkType=child|Translit=rāmāyaṇa'] 10\n",
      "[''] 1\n",
      "True\n",
      "2\tकाल\tकाल\tPROPN\tNNP\tCase=Acc|Gender=Masc|Number=Sing|Person=3\t23\tobl\t_\tVib=0_में|Tam=0|ChunkId=NP|ChunkType=head|Translit=kāla\n",
      "['2', 'काल', 'काल', 'PROPN', 'NNP', 'Case=Acc|Gender=Masc|Number=Sing|Person=3', '23', 'obl', '_', 'Vib=0_में|Tam=0|ChunkId=NP|ChunkType=head|Translit=kāla']\n",
      "काल NNP Case=Acc|Gender=Masc|Number=Sing|Person=3 obl Vib=0_में|Tam=0|ChunkId=NP|ChunkType=head|Translit=kāla\n",
      "Case=Acc|Gender=Masc|Number=Sing|Person=3|Vib=0_में|Tam=0|ChunkId=NP|ChunkType=head|Translit=kāla\n",
      "[0, 4978, 0, 0, 0, 0, 0, 0, 0, 0, 35217, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Case=Acc', 'Gender=Masc', 'Number=Sing', 'Person=3', 'Vib=0_में', 'Tam=0', 'ChunkId=NP', 'ChunkType=head', 'Translit=kāla']\n",
      "Acc\n"
     ]
    }
   ],
   "source": [
    "with open('UDData/Development/hi_hdtb-ud-dev.conllu.txt', 'r') as f:\n",
    "    t = f.read()\n",
    "    t = t.split('\\n')\n",
    "    print(t[0].split('\\t'), len(t[0].split('\\t')))\n",
    "    print(t[1].split('\\t'), len(t[1].split('\\t')))\n",
    "    print(t[2].split('\\t'), len(t[2].split('\\t')))\n",
    "    print(t[26].split('\\t'), len(t[26].split('\\t')))\n",
    "    print(t[26].split('\\t')[0] == '')\n",
    "    print(t[3])\n",
    "    print(t[3].split('\\t'))\n",
    "    m = t[3].split('\\t')\n",
    "    print(m[1], m[4], m[5], m[7], m[9])\n",
    "    print(m[5]+'|'+m[9])\n",
    "    lengths = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for line in t:\n",
    "        line = line.split('\\t')\n",
    "        lengths[len(line)] += 1\n",
    "    print(lengths)\n",
    "    text = m[5]+'|'+m[9]\n",
    "    print(text.split('|'))\n",
    "    print(text.split('|')[0].split('=')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files in directory:  /home/zubair/Documents/Work/Acads/Semester6/subjects/LData/Assignment/Project/Code/udmodules/UDData/Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320970/320970 [00:02<00:00, 122439.92it/s]\n",
      " 35%|███▌      | 14085/40195 [00:00<00:00, 140849.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files in directory:  /home/zubair/Documents/Work/Acads/Semester6/subjects/LData/Assignment/Project/Code/udmodules/UDData/Development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40195/40195 [00:00<00:00, 123588.78it/s]\n",
      " 22%|██▏       | 8957/40483 [00:00<00:00, 89569.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files in directory:  /home/zubair/Documents/Work/Acads/Semester6/subjects/LData/Assignment/Project/Code/udmodules/UDData/Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40483/40483 [00:00<00:00, 96183.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testfile written\n"
     ]
    }
   ],
   "source": [
    "def get_features(pos, featurelist, word):\n",
    "    featuredict = {}\n",
    "    featuredict['pos'] = pos\n",
    "    featuredict['word'] = word\n",
    "    featuresplit = featurelist.split('|')\n",
    "    for feature in featuresplit:\n",
    "        if '=' in feature:\n",
    "#             print(feature)\n",
    "            key = feature.split('=')[0]\n",
    "            val = feature.split('=')[1]\n",
    "#         if not (key == 'stype' or key == 'voicetype' or key == 'chunkType' or key == 'chunkId'):\n",
    "            featuredict[key] = val\n",
    "#         else:\n",
    "#             print(feature)\n",
    "    return featuredict\n",
    "    \n",
    "for current in subdirs:\n",
    "    all_sentences = []\n",
    "    all_features = []\n",
    "    all_ud_tags = []\n",
    "    \n",
    "    directory = os.path.join(dir_prefix, current)\n",
    "    print(\"processing files in directory: \", directory)\n",
    "    for file in os.listdir(directory):\n",
    "        file = os.path.join(directory, file)\n",
    "        with open(file) as readfile:\n",
    "            filerows = readfile.read().split('\\n')\n",
    "            \n",
    "            sentence = []\n",
    "            ud_tags = []\n",
    "            features = []\n",
    "            \n",
    "            for row in tqdm(filerows):\n",
    "                row = row.split('\\t')\n",
    "            \n",
    "                if len(row) == 1 and row[0] == '':\n",
    "                    all_sentences.append(sentence)\n",
    "                    all_features.append(features)\n",
    "                    all_ud_tags.append(ud_tags)\n",
    "                    \n",
    "                    sentence = []\n",
    "                    features = []\n",
    "                    ud_tags = []\n",
    "                elif len(row) == 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        sentence.append(row[1])\n",
    "                        features.append(get_features(row[4], row[5]+'|'+row[9], row[1]))\n",
    "                        ud_tags.append(row[7])\n",
    "                    except:\n",
    "                        print(\"Error with sentence in file:\", file, \", no need to interfere\")\n",
    "    datadir = os.path.join(os.getcwd(), 'Data/')                    \n",
    "    with open(datadir+current+'_sentences.pkl', 'wb') as dump:\n",
    "        pickle.dump(all_sentences, dump)\n",
    "    with open(datadir+current+'_features.pkl', 'wb') as dump:\n",
    "        pickle.dump(all_features, dump)\n",
    "    with open(datadir+current+'_ud_tags.pkl', 'wb') as dump:\n",
    "        pickle.dump(all_ud_tags, dump)\n",
    "        \n",
    "    if current == 'Testing':\n",
    "        testcases = {}\n",
    "        testcases['sentences'] = all_sentences\n",
    "        testcases['ud'] = all_ud_tags\n",
    "        testcases['features'] = all_features\n",
    "        with open('testfile.pkl', 'wb') as testfile:\n",
    "            pickle.dump(testcases, testfile)\n",
    "        print('testfile written')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('AnnCorra/Training/fullnews_id_2575975_date_7_7_2004.dat', newline='') as csvfile:\n",
    "#     csvreader = csv.reader(csvfile, delimiter='\\t')\n",
    "#     for row in csvreader:\n",
    "#         if len(row) > 0:\n",
    "#             print(row[1], row[4], row[5].split('|'), row[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1685\n",
      "[{'pos': 'NNP', 'word': 'भैरव', 'Case': 'Acc', 'Gender': 'Masc', 'Number': 'Sing', 'Person': '3', 'Vib': '0_का', 'Tam': '0', 'ChunkId': 'NP', 'ChunkType': 'head', 'Translit': 'bhairava'}, {'pos': 'PSP', 'word': 'का', 'AdpType': 'Post', 'Case': 'Nom', 'Gender': 'Masc', 'Number': 'Sing', 'ChunkId': 'NP', 'ChunkType': 'child', 'Translit': 'kā'}, {'pos': 'NN', 'word': 'स्थान', 'Case': 'Nom', 'Gender': 'Masc', 'Number': 'Sing', 'Person': '3', 'Vib': '0', 'Tam': '0', 'ChunkId': 'NP2', 'ChunkType': 'head', 'Translit': 'sthāna'}, {'pos': 'NNP', 'word': 'उत्तराखंड', 'Case': 'Acc', 'Gender': 'Masc', 'Number': 'Sing', 'Person': '3', 'Vib': '0_में', 'Tam': '0', 'ChunkId': 'NP3', 'ChunkType': 'head', 'Translit': 'uttarākhaṁḍa'}, {'pos': 'PSP', 'word': 'में', 'AdpType': 'Post', 'ChunkId': 'NP3', 'ChunkType': 'child', 'Translit': 'meṁ'}, {'pos': 'NNP', 'word': 'क्षेत्रपाल', 'Case': 'Acc', 'Gender': 'Masc', 'Number': 'Sing', 'Person': '3', 'Vib': '0', 'Tam': '0', 'ChunkId': 'NP4', 'ChunkType': 'head', 'Translit': 'kṣetrapāla'}, {'pos': 'CC', 'word': 'अथवा', 'ChunkId': 'CCP', 'ChunkType': 'head', 'Translit': 'athavā'}, {'pos': 'NNP', 'word': 'भूमिदेव', 'Case': 'Acc', 'Gender': 'Masc', 'Number': 'Sing', 'Person': '3', 'Vib': '0_के_रूप_में', 'Tam': '0', 'ChunkId': 'NP5', 'ChunkType': 'head', 'Translit': 'bhūmideva'}, {'pos': 'PSP', 'word': 'के', 'AdpType': 'Post', 'Case': 'Acc', 'Gender': 'Masc', 'ChunkId': 'NP5', 'ChunkType': 'child', 'Translit': 'ke'}, {'pos': 'PSP', 'word': 'रूप', 'Case': 'Acc', 'Gender': 'Masc', 'ChunkId': 'NP5', 'ChunkType': 'child', 'Translit': 'rūpa'}, {'pos': 'PSP', 'word': 'में', 'AdpType': 'Post', 'ChunkId': 'NP5', 'ChunkType': 'child', 'Translit': 'meṁ'}, {'pos': 'JJ', 'word': 'महत्वपूर्ण', 'ChunkId': 'JJP', 'ChunkType': 'head', 'Translit': 'mahatvapūrṇa'}, {'pos': 'VM', 'word': 'है', 'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin', 'Voice': 'Act', 'Vib': 'है', 'Tam': 'hE', 'ChunkId': 'VGF', 'ChunkType': 'head', 'Stype': 'declarative', 'Translit': 'hai'}, {'pos': 'SYM', 'word': '।', 'ChunkId': 'BLK', 'ChunkType': 'head', 'Translit': '.'}]\n"
     ]
    }
   ],
   "source": [
    "with open('Data/Testing_features.pkl', 'rb') as pickled:\n",
    "    newlist = pickle.load(pickled)\n",
    "print(len(newlist))\n",
    "print(newlist[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
